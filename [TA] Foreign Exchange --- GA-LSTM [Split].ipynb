{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport datetime, pytz\n\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense\nfrom keras.metrics import RootMeanSquaredError\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:30:43.537665Z","iopub.execute_input":"2023-09-23T09:30:43.538133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameter","metadata":{}},{"cell_type":"code","source":"SEQ_LEN = 21 # 6, 11, 21\nSPLIT = 0.90 # 0.80, 0.90\nLSTM_Layer = 1 # 1, 2, 3\nWINDOW_SIZE = SEQ_LEN - 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Google Spreadsheet ID\nSHEET_ID = '1JDNv_mArl-GPIpxuWS5GxgVEwvjXocS1MrXGc6TYs8M'\nSHEET_NAME = ['USD/IDR', 'EUR/IDR', 'JPY/IDR']\n\nurl = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME[0]}'\ndata = pd.read_csv(url)\n\n# Convert Date columns to datetime format\ndata['Date'] = pd.to_datetime(data['Date'], format='%d/%m/%Y %H:%M:%S')\ndata.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"scaler = MinMaxScaler()\nclose_price = data.Close.values.reshape(-1, 1)\nscaled_close = scaler.fit_transform(close_price)\nscaled_close.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_sequences(data, seq_len):\n    d = []\n    for index in range(len(data) - seq_len):\n        d.append(data[index: index + seq_len])\n    return np.array(d)\n\ndef preprocess(data_raw, seq_len, train_split):\n    data = to_sequences(data_raw, seq_len)\n    num_train = int(train_split * data.shape[0])\n    X_train = data[:num_train, :-1, :]\n    y_train = data[:num_train, -1, :]\n    X_test = data[num_train:, :-1, :]\n    y_test = data[num_train:, -1, :]\n    return X_train, y_train, X_test, y_test\n\nX_train, y_train, X_test, y_test = preprocess(scaled_close, SEQ_LEN, train_split = SPLIT)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Genetic Algorithm","metadata":{}},{"cell_type":"code","source":"# Genetic Algorithm\ndef genetic_algorithm(population_size, generations):\n    population = np.random.randint(1, high=26, size=(population_size, 3))\n    \n    for generation in range(generations):\n        print(f\"Generation - {generation + 1}\")\n        fitness_scores = np.array([fitness_function(chromosome) for chromosome in population])\n        best_chromosome = population[np.argmax(fitness_scores)]\n        best_fitness = np.max(fitness_scores)\n        \n        new_population = []\n        \n        while len(new_population) < population_size:\n            parent1 = selection(population, fitness_scores)\n            parent2 = selection(population, fitness_scores)\n            offspring_1, offspring_2 = crossover(parent1, parent2)\n            mutate(offspring_1)\n            mutate(offspring_2)\n            new_population.append(offspring_1)\n            new_population.append(offspring_2)\n        \n        population = np.array(new_population)\n    \n    return best_chromosome, best_fitness\n\n# Selection (Tournament selection)\ndef selection(population, fitness_scores, tournament_size=3):\n    indices = np.random.randint(len(population), size=tournament_size)\n    tournament = population[indices]\n    tournament_fitness = fitness_scores[indices]\n    return tournament[np.argmax(tournament_fitness)]\n\n# Crossover (Single-point crossover)\ndef crossover(parent1, parent2):\n    crossover_point = np.random.randint(1, len(parent1))\n    offspring_1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n    offspring_2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n    return offspring_1, offspring_2\n\n# Mutation (Swap Mutation)\ndef mutate(chromosome, mutation_rate=0.01):\n    for i in range(len(chromosome)):\n        if np.random.rand() < mutation_rate:\n            j = np.random.randint(len(chromosome))\n            chromosome[i], chromosome[j] = chromosome[j], chromosome[i]\n\n# Define the fitness function to be optimized\ndef fitness_function(chromosome):\n    lstm_units = [int(chromosome[i]*10) or default for i, default in enumerate([128, 64, 32])]\n\n    # Build the LSTM model\n    model = Sequential()\n    for i, units in enumerate(lstm_units[:LSTM_Layer]):\n        model.add(LSTM(units, return_sequences=(i < LSTM_Layer - 1), input_shape=(WINDOW_SIZE, 1)))\n    model.add(Dense(1))\n    \n    # Compile and train the model\n    model.compile(loss='mean_squared_error',\n                  optimizer='adam')\n    model.fit(X_train,\n              y_train,\n              epochs=10,\n              batch_size=32,\n              verbose=0,\n              validation_split=0.1)\n\n    # Evaluate the model\n    loss = model.evaluate(X_test, y_test)\n\n    # Return the negative value of the loss as the fitness score\n    return -loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import typing\nfrom datetime import datetime\n\ndef timer(start_time: datetime = None) -> \"typing.Union[datetime.datetime, str]\":\n    if not start_time:\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n        tmin, tsec = divmod(temp_sec, 60)\n        return \"%i hours %i minutes and %s seconds.\" % (\n            thour,\n            tmin,\n            round(tsec, 2),\n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Do not increase this value\npopulation_size = 5\ngenerations = 25\n\ntime = timer(None)\nbest_chromosome, best_fitness = genetic_algorithm(population_size, generations)\ntime = timer(time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Best Chromosome:\", best_chromosome)\nprint(\"Best Fitness:\", best_fitness)\nprint(\"Time Taken:\", time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Re-Training Model with Best Parameter","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nfor i, units in enumerate(best_chromosome[:LSTM_Layer]):\n    model.add(LSTM(units*10, return_sequences=(i < LSTM_Layer - 1), input_shape=(WINDOW_SIZE, 1)))\nmodel.add(Dense(1))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:09:42.470468Z","iopub.execute_input":"2023-09-21T08:09:42.470860Z","iopub.status.idle":"2023-09-21T08:09:42.769299Z","shell.execute_reply.started":"2023-09-21T08:09:42.470824Z","shell.execute_reply":"2023-09-21T08:09:42.768320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='mean_squared_error',\n              metrics=['mae', RootMeanSquaredError()],\n              optimizer='adam')\n\nhistory = model.fit(X_train,\n                    y_train,\n                    epochs=50,\n                    batch_size=32,\n                    validation_split=0.1)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:09:42.770724Z","iopub.execute_input":"2023-09-21T08:09:42.771055Z","iopub.status.idle":"2023-09-21T08:10:06.096591Z","shell.execute_reply.started":"2023-09-21T08:09:42.771021Z","shell.execute_reply":"2023-09-21T08:10:06.095587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:10:06.100868Z","iopub.execute_input":"2023-09-21T08:10:06.101165Z","iopub.status.idle":"2023-09-21T08:10:06.197857Z","shell.execute_reply.started":"2023-09-21T08:10:06.101139Z","shell.execute_reply":"2023-09-21T08:10:06.196711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title(f'{SHEET_NAME[0]} Model Loss', fontsize=15)\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:10:06.200373Z","iopub.execute_input":"2023-09-21T08:10:06.200781Z","iopub.status.idle":"2023-09-21T08:10:06.561495Z","shell.execute_reply.started":"2023-09-21T08:10:06.200744Z","shell.execute_reply":"2023-09-21T08:10:06.560343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_hat = model.predict(X_test)\ny_test_inverse = scaler.inverse_transform(y_test)\ny_hat_inverse = scaler.inverse_transform(y_hat)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:10:06.563218Z","iopub.execute_input":"2023-09-21T08:10:06.564022Z","iopub.status.idle":"2023-09-21T08:10:07.112518Z","shell.execute_reply.started":"2023-09-21T08:10:06.563980Z","shell.execute_reply":"2023-09-21T08:10:07.111453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(y_test_inverse, label=\"Actual Price\", color='green')\nplt.plot(y_hat_inverse, label=\"Predicted Price\", color='red')\n \nplt.title(f'{SHEET_NAME[0]} Price Prediction\\nLSTM = {LSTM_Layer}, Split Data = {SPLIT}, Window = {WINDOW_SIZE}', fontsize=15)\nplt.xlabel('Time [days]')\nplt.ylabel('Price')\nplt.legend(loc='best')\n \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:10:07.114157Z","iopub.execute_input":"2023-09-21T08:10:07.114580Z","iopub.status.idle":"2023-09-21T08:10:07.459437Z","shell.execute_reply.started":"2023-09-21T08:10:07.114544Z","shell.execute_reply":"2023-09-21T08:10:07.458212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def matrices(actual, predicted):\n    mse = mean_squared_error(actual, predicted)\n    mae = mean_absolute_error(actual, predicted)\n    rmse = np.sqrt(mse)\n    print(\"Mean Absolute Error for prediction :\", mae)\n    print(\"Mean Squared Error for prediction :\", mse)\n    print(\"Root Mean Squared Error for prediction :\", rmse)\n    return mae, mse, rmse\n\nprint(f\"LSTM = {LSTM_Layer}, Split Data = {SPLIT}, Window = {WINDOW_SIZE}\")\nprint(\"\\n----------------- Normalized Error -----------------\")\nmae, mse, rmse = matrices(y_test, y_hat)\nprint(\"\\n----------------- Actual Error -----------------\")\nmae_inverse, mse_inverse, rmse_inverse = matrices(y_test_inverse, y_hat_inverse)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:10:07.460366Z","iopub.execute_input":"2023-09-21T08:10:07.462670Z","iopub.status.idle":"2023-09-21T08:10:07.473862Z","shell.execute_reply.started":"2023-09-21T08:10:07.462635Z","shell.execute_reply":"2023-09-21T08:10:07.471767Z"},"trusted":true},"execution_count":null,"outputs":[]}]}