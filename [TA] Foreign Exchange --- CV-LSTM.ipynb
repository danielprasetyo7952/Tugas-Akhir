{"cells":[{"cell_type":"markdown","metadata":{"id":"eINAHj9aOXeg"},"source":["# Foreign Exchange Forecasting using LSTMs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cx2zF1XfOV_P","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM\n","from keras.metrics import RootMeanSquaredError\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.metrics import mean_squared_error, mean_absolute_error"]},{"cell_type":"markdown","metadata":{},"source":["## Hyperparameter"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Google Spreadsheet ID\n","SHEET_ID = '1JDNv_mArl-GPIpxuWS5GxgVEwvjXocS1MrXGc6TYs8M'\n","SHEET_NAME = 'SGD/IDR' # 'USD/IDR', 'EUR/IDR', 'SGD/IDR'\n","\n","SEQ_LEN = 6 # 6, 11, 21\n","FOLD = 5 # 5, 10\n","LSTM_Layer = 2 # 1, 2, 3\n","WINDOW_SIZE = SEQ_LEN - 1"]},{"cell_type":"markdown","metadata":{"id":"gCuiJ0AZkVlF"},"source":["## Data Overview\n","From Google Finance"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"bUHoPiYSPgR0","outputId":"67321f7e-2677-4f61-c658-65c61836c061","trusted":true},"outputs":[],"source":["url = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n","df = pd.read_csv(url)\n","\n","# Convert Date columns to datetime format\n","df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y %H:%M:%S')\n","df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":554},"id":"cg0J1iJR90mN","outputId":"d31df7c4-8528-469a-fde6-2c350b9fd16f","trusted":true},"outputs":[],"source":["dfplot = df.copy()\n","dfplot = dfplot.groupby([pd.Grouper(key='Date', freq='D')]).first().reset_index()\n","dfplot = dfplot.set_index('Date')\n","\n","color_pal = [\"#F8766D\", \"#D39200\", \"#93AA00\", \"#00BA38\", \"#00C19F\", \"#00B9E3\", \"#619CFF\", \"#DB72FB\"]\n","_ = dfplot.plot(style='', figsize=(20,5), color=color_pal[0], title=f'{SHEET_NAME} by Days')"]},{"cell_type":"markdown","metadata":{"id":"-fmM4iPRkvbm"},"source":["## Data preprocessing"]},{"cell_type":"markdown","metadata":{},"source":["### Outlier Detection"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def replace_outliers(data):\n","    \"\"\"\n","    Replaces outliers in a given dataset with the lower/upper bound value.\n","\n","    Args:\n","        data: A numpy array or pandas DataFrame containing the data.\n","\n","    Returns:\n","        A numpy array with outliers replaced by the lower/upper bound value.\n","    \"\"\"\n","    Q1 = np.percentile(data, 25)\n","    Q3 = np.percentile(data, 75)\n","    IQR = Q3 - Q1\n","    lower_bound = Q1 - 1.5 * IQR\n","    upper_bound = Q3 + 1.5 * IQR\n","    data[data < lower_bound] = lower_bound\n","    data[data > upper_bound] = upper_bound\n","    return data\n","\n","df['Close'] = replace_outliers(df['Close'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Boxplot for outlier detection\n","plt.boxplot(df['Close'])\n","plt.title(f\"{SHEET_NAME} Boxplot for Outlier Detection\")\n","plt.xlabel(\"Close\")\n","plt.ylabel(\"Values\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Normalize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oujHEBWrO_nD","trusted":true},"outputs":[],"source":["scaler = MinMaxScaler()\n","close_price = df.Close.values.reshape(-1, 1)\n","scaled_close = scaler.fit_transform(close_price)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"----------- Normalize Data Shape -----------\")\n","print(scaled_close.shape)\n","print(\"\\n----------- Normalize Data -----------\")\n","print(scaled_close)"]},{"cell_type":"markdown","metadata":{"id":"T2XMIFHEkyQl"},"source":["### Sliding Window and TSCV"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kSv2rZPBQBPZ","trusted":true},"outputs":[],"source":["def to_sequences(data, seq_len):\n","    \"\"\"\n","    Converts a list of data into a sequence of equal length.\n","\n","    Args:\n","        data: A list of numerical values.\n","        seq_len: An integer indicating the length of each sequence.\n","\n","    Returns:\n","        A numpy array of shape (len(data) - seq_len, seq_len) containing the sequences.\n","    \"\"\"\n","    d = []\n","    for index in range(len(data) - seq_len):\n","        d.append(data[index: index + seq_len])\n","    return np.array(d)\n","\n","def preprocess(data_raw, seq_len):\n","    \"\"\"\n","    Preprocesses the raw data into training data and target labels.\n","\n","    Args:\n","        data_raw: A list of numerical values.\n","        seq_len: An integer indicating the length of each sequence.\n","\n","    Returns:\n","        A tuple of two numpy arrays: (train, target).\n","        train is the input data for training, with shape (len(data_raw) - seq_len, seq_len - 1).\n","        target is the output labels for training, with shape (len(data_raw) - seq_len, 1).\n","    \"\"\"\n","    data = to_sequences(data_raw, seq_len)\n","    target = data[:, -1, :]\n","    input = data[:, :-1, :]\n","    return input, target\n","    \n","inputs, targets = preprocess(scaled_close, SEQ_LEN)\n","\n","tscv = TimeSeriesSplit(n_splits=FOLD)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["i = 1\n","for train, test in tscv.split(inputs, targets):\n","    print(f\"Fold No - {i}\")\n","    print(f\"----------- Train Data Shape -----------\")\n","    print(inputs[train].shape)\n","    print(targets[train].shape)\n","    print(f\"----------- Test Data Shape -----------\")\n","    print(inputs[test].shape)\n","    print(targets[test].shape)\n","    print()\n","    i += 1"]},{"cell_type":"markdown","metadata":{},"source":["## Modeling"]},{"cell_type":"markdown","metadata":{"id":"WYBNKAhSk3z-"},"source":["### Building LSTM Model with Cross-Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["BATCH_SIZE = 32\n","VAL_SPLIT = 0.1\n","EPOCH = 50\n","\n","metrics_per_fold = [[] for _ in range(3)]\n","metrics_inverse_per_fold = [[] for _ in range(3)]\n","y_test_per_fold, y_hat_inverse_per_fold = [], []\n","history_per_fold = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kynIZjUTQfto","trusted":true},"outputs":[],"source":["for fold_no, (train, test) in enumerate(tscv.split(inputs, targets)):\n","    tf.keras.backend.clear_session()\n","    \n","    model = Sequential()\n","    for i, units in enumerate([128, 64, 32][:LSTM_Layer]):\n","        model.add(LSTM(units, return_sequences=(i < LSTM_Layer - 1), input_shape=(WINDOW_SIZE, 1)))\n","    model.add(Dense(1))\n","    \n","    model.compile(loss='mean_squared_error',\n","                  metrics=['mae', RootMeanSquaredError()],\n","                  optimizer='adam')\n","\n","    print('------------------------------------------------------------------------')\n","    print(f'Training for fold {fold_no+1} ...')\n","    \n","    history = model.fit(inputs[train],\n","                        targets[train],\n","                        epochs=EPOCH,\n","                        batch_size=BATCH_SIZE,\n","                        validation_split=VAL_SPLIT,\n","                        verbose=0)\n","    \n","    history_per_fold.append(history)\n","    \n","    # Model Evaluation\n","    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n","    \n","    # Model Prediction\n","    y_hat = model.predict(inputs[test])\n","    y_test_inverse = scaler.inverse_transform(targets[test])\n","    y_hat_inverse = scaler.inverse_transform(y_hat)\n","    \n","    y_test_per_fold.append(y_test_inverse)\n","    y_hat_inverse_per_fold.append(y_hat_inverse)\n","    \n","    # Model Prediction Metrics\n","    mse_inverse = mean_squared_error(y_test_inverse, y_hat_inverse)\n","    mae_inverse = mean_absolute_error(y_test_inverse, y_hat_inverse)\n","    rmse_inverse = np.sqrt(mse_inverse)\n","       \n","    mse = mean_squared_error(targets[test], y_hat)\n","    mae = mean_absolute_error(targets[test], y_hat)\n","    rmse = np.sqrt(mse)\n","\n","    print(\"Model Evaluate (model.evaluate) Result\")\n","    print(f'Score for fold {fold_no+1}: {model.metrics_names[1]} is {scores[1]}; {model.metrics_names[0]}/mse is {scores[0]}; {model.metrics_names[2]} is {scores[2]}\\n')\n","    \n","    print(\"Model Predict (model.predict) Result\")\n","    print(f'Score for fold {fold_no+1}: mae is {mae}; mse is {mse}; rmse is {rmse}')\n","    print(f'Score for fold {fold_no+1}: mae is {mae_inverse}; mse is {mse_inverse}; rmse is {rmse_inverse}\\n')\n","\n","    metrics_inverse_per_fold[0].append(mae_inverse) # MAE Inverse\n","    metrics_inverse_per_fold[1].append(mse_inverse) # MSE Inverse\n","    metrics_inverse_per_fold[2].append(rmse_inverse) # RMSE Inverse\n","    \n","    metrics_per_fold[0].append(mae) # MAE\n","    metrics_per_fold[1].append(mse) # MSE\n","    metrics_per_fold[2].append(rmse) # RMSE"]},{"cell_type":"markdown","metadata":{},"source":["## Model Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["title = ['MAE', 'MSE', 'RMSE']\n","for i, unit in enumerate(metrics_per_fold):\n","    print(f\"----------- {title[i]} -----------\")\n","    print(f\"Value per Fold : {unit}\")\n","    print(f\"Average Training Value : {np.mean(unit)}\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for i, unit in enumerate(metrics_inverse_per_fold):\n","    print(f\"----------- {title[i]} -----------\")\n","    print(f\"Value per Fold : {unit}\")\n","    print(f\"Average Training Value : {np.mean(unit)}\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":535},"id":"LDxMFgnAmMOm","outputId":"25ed3650-be5c-4232-f5f7-b1f8bcc61eb1","trusted":true},"outputs":[],"source":["fig, axs = plt.subplots(FOLD, figsize=(12, FOLD*5))\n","for i in range(FOLD):\n","    axs[i].plot(history_per_fold[0].history['loss'])\n","    axs[i].plot(history_per_fold[0].history['val_loss'])\n","\n","    axs[i].set_title(f'{SHEET_NAME} Model Loss --- Fold {i+1}')\n","    axs[i].set_xlabel('epoch')\n","    axs[i].set_ylabel('loss')\n","    axs[i].legend(['train', 'test'], loc='best')\n","\n","plt.tight_layout()\n","plt.savefig(f'D:/Collage/Courses/Skripsi/Gambar/Hasil Skenario/{SHEET_NAME[:3]} Model Loss_LSTM_{LSTM_Layer}_CV_{FOLD}_Window_{WINDOW_SIZE}.png')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":535},"id":"leSupqhPoEX1","outputId":"8864e9ef-a20c-4ef1-9dcf-78dd87a2bf06","trusted":true},"outputs":[],"source":["fig, axs = plt.subplots(FOLD, figsize=(12, FOLD*5))\n","for i in range(FOLD):\n","    axs[i].plot(y_test_per_fold[i], label=\"Actual Price\", color='green')\n","    axs[i].plot(y_hat_inverse_per_fold[i], label=\"Predicted Price\", color='red')\n","\n","    axs[i].set_title(f'{SHEET_NAME} Price Prediction --- Fold {i+1}')\n","    axs[i].set_xlabel('Time [days]')\n","    axs[i].set_ylabel('Price')\n","    axs[i].legend(loc='best')\n","\n","plt.tight_layout()\n","plt.savefig(f'D:/Collage/Courses/Skripsi/Gambar/Hasil Skenario/{SHEET_NAME[:3]} Price Prediction_LSTM_{LSTM_Layer}_CV_{FOLD}_Window_{WINDOW_SIZE}.png')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["error_result = pd.DataFrame([[SHEET_NAME, LSTM_Layer, WINDOW_SIZE, np.nan, FOLD, np.mean(metrics_inverse_per_fold[0]), np.mean(metrics_inverse_per_fold[1]), np.mean(metrics_inverse_per_fold[2])]],\n","                            columns=['Type', 'LSTM Layer', 'Window', 'Split', 'CV (Fold)', 'MAE', 'MSE', 'RMSE'])\n","hasil = pd.read_excel('Hasil - 2.0.xlsx')\n","final = pd.concat([hasil, error_result], ignore_index=True)\n","final.to_excel('Hasil - 2.0.xlsx', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import playsound\n","\n","playsound.playsound('C:/Users/danie/Downloads/Music/iphone_14.mp3')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"}},"nbformat":4,"nbformat_minor":4}
